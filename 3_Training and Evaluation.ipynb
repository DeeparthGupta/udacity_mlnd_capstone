{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying urban sounds using deep learning models.\n",
    "## Model Training and Evaluation\n",
    "### Load preprocessed data\n",
    "\n",
    "The data is loaded from a .dat file that contains prepocessed data that was previously created. After loading the data will be split into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve contents of the .dat file stored in the data folder\n",
    "\n",
    "import pickle\n",
    "\n",
    "file_path = 'data/serial_dataset.pickle'\n",
    "with open(file_path, \"rb\") as f:\n",
    "    contents = pickle.load(f)\n",
    "\n",
    "X = contents[0]\n",
    "y = contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is split into training and testing sets.\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8732, 8732)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network model architecture\n",
    "CNNs are some of the best tools for image classification do to their ability to quantify spatial relationships. \n",
    "Our architecture will be a relatively small `Sequential`model consisting of 3 `Conv2D`convolution layers each followed by a `Pool2D` pooling layer. Finally, the output is from a `Dense` layer connected to the Convolutional.\n",
    "    \n",
    "The convolutional layer perform the actual feature selection. It slides a small window(aka kernek aka filter) with weights on it over the pixels of the image. It starts at the top and performs summation matrix operations and saves the result as part of an activation map. This process is called convolution. The filter parameter specifies the number of filters that will be applied to a layer in the CNN. Each layer of a CNN can have many filters. Each filter learns something differnt about the problem statment and crosses the activation threshold for different inputs.\n",
    "\n",
    "The pooling layers reduce dimensionality wihout much loss in data. This increases robustness of the model and lowers its compute and storage requirements. Two type of pooling layers will be used in the model. Firstly, `Pool2D` will be used between Convolutional layers to reduce dimensionality while preserving spatial information. \n",
    "\n",
    "After features are extracted, they are fed into a `GlobalAveragePooling2D` layer to flatten the features into a vector while preserving more information than simply flattening it with the `Flatten` layer.\n",
    "\n",
    "The output layer will have 10 nodes which matches the number of target classes. The `Softmax` activation function will used on the output layer giving us a vector of probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, GlobalAveragePooling2D \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "width = 40\n",
    "height = 175\n",
    "channels = 1\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],width,height,channels)\n",
    "X_test = X_test.reshape(X_test.shape[0],width,height,channels)\n",
    "\n",
    "label_count = y.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(filters=16,kernel_size=2,input_shape=(width,height,channels),activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=32,kernel_size=2,activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=64,kernel_size=2,activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Conv2D(filters=128,kernel_size=2,activation='relu'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    \n",
    "    Dense(label_count,activation='softmax')\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 174, 16)       80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 87, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 87, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 86, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 43, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 9, 43, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 42, 64)         8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 21, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 21, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 20, 128)        32896     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 44,602\n",
      "Trainable params: 44,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1747/1747 [==============================] - 1s 777us/step\n",
      "Pretraining accuracy:10.8185%\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "model.summary()\n",
    "\n",
    "#pretraining_accuracy\n",
    "score = model.evaluate(X_test,y_test,verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print('Pretraining accuracy:%.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The training of the model begins. CNNs are best trained on the GPU because of their high parallelization capability. One can train lower epoch numbers on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.77160, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 2.77160 to 1.71385, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 1.71385 to 1.44300, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00004: loss improved from 1.44300 to 1.29350, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 1.29350 to 1.20973, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 1.20973 to 1.13178, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: loss improved from 1.13178 to 1.08166, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 1.08166 to 1.00517, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 1.00517 to 0.96583, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00010: loss improved from 0.96583 to 0.91061, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00011: loss improved from 0.91061 to 0.84592, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: loss improved from 0.84592 to 0.81191, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00013: loss improved from 0.81191 to 0.77506, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00014: loss improved from 0.77506 to 0.72310, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00015: loss improved from 0.72310 to 0.68690, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00016: loss improved from 0.68690 to 0.65987, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00017: loss improved from 0.65987 to 0.64050, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00018: loss improved from 0.64050 to 0.59479, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00019: loss improved from 0.59479 to 0.58414, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.58414\n",
      "\n",
      "Epoch 00021: loss improved from 0.58414 to 0.55447, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00022: loss improved from 0.55447 to 0.51631, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.51631\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00024: loss improved from 0.51631 to 0.47065, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00025: loss improved from 0.47065 to 0.41894, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00026: loss improved from 0.41894 to 0.41193, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00027: loss improved from 0.41193 to 0.40124, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00028: loss improved from 0.40124 to 0.39736, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00029: loss improved from 0.39736 to 0.39590, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00030: loss improved from 0.39590 to 0.39346, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.39346\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.39346\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.51642, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.51642 to 0.45098, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 0.45098 to 0.43150, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.43150\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00005: loss improved from 0.43150 to 0.41559, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.41559 to 0.35066, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: loss improved from 0.35066 to 0.33460, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 0.33460 to 0.33090, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 0.33090 to 0.32582, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.32582\n",
      "\n",
      "Epoch 00011: loss improved from 0.32582 to 0.31679, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00012: loss improved from 0.31679 to 0.31047, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.31047\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00014: loss improved from 0.31047 to 0.30892, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.30892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.30892\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.30892\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.42051, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.42051 to 0.35780, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.35780\n",
      "\n",
      "Epoch 00004: loss improved from 0.35780 to 0.30662, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 0.30662 to 0.28420, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.28420 to 0.27653, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.27653\n",
      "\n",
      "Epoch 00008: loss improved from 0.27653 to 0.27353, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.27353\n",
      "\n",
      "Epoch 00010: loss improved from 0.27353 to 0.27328, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00011: loss improved from 0.27328 to 0.27174, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.27174\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.27174\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.27174\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00015: loss improved from 0.27174 to 0.26676, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.26676\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00023: loss improved from 0.26676 to 0.26598, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.26598\n",
      "\n",
      "Epoch 00036: loss improved from 0.26598 to 0.26435, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.26435\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.26435\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.37332, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.37332 to 0.33567, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 0.33567 to 0.31712, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00004: loss improved from 0.31712 to 0.31483, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 0.31483 to 0.30122, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00006: loss improved from 0.30122 to 0.28200, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: loss improved from 0.28200 to 0.23721, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 0.23721 to 0.22251, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 0.22251 to 0.21586, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.21586\n",
      "\n",
      "Epoch 00011: loss improved from 0.21586 to 0.21392, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00012: loss improved from 0.21392 to 0.21225, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00013: loss improved from 0.21225 to 0.20761, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.20761\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00022: loss improved from 0.20761 to 0.20375, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.20375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.20375\n",
      "\n",
      "Epoch 00047: loss improved from 0.20375 to 0.20318, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.20318\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.20318\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.20318\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.31151, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.31151 to 0.26568, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.26568\n",
      "\n",
      "Epoch 00004: loss improved from 0.26568 to 0.23776, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 0.23776 to 0.20518, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.20518 to 0.20064, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00007: loss improved from 0.20064 to 0.19804, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 0.19804 to 0.19198, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00009: loss improved from 0.19198 to 0.18644, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.18644\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.18644\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.18644\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.18644\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.18644\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00015: loss improved from 0.18644 to 0.18266, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.18266\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00027: loss improved from 0.18266 to 0.17993, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001428009978e-26.\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.17993\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.17993\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.27962, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.27962 to 0.25357, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 0.25357 to 0.24763, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: loss improved from 0.24763 to 0.24644, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 0.24644 to 0.18822, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.18822 to 0.16705, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.16705\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.16705\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.16705\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.16705\n",
      "\n",
      "Epoch 00011: loss improved from 0.16705 to 0.15967, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.15967\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.15967\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00014: loss improved from 0.15967 to 0.15429, saving model to ./best_model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: loss did not improve from 0.15429\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.15429\n",
      "\n",
      "Epoch 00017: loss improved from 0.15429 to 0.15228, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00018: loss improved from 0.15228 to 0.14789, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.14789\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.14789\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.25102, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.25102 to 0.20273, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.20273\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: loss improved from 0.20273 to 0.19534, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss improved from 0.19534 to 0.15898, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00006: loss improved from 0.15898 to 0.15287, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: loss improved from 0.15287 to 0.14466, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 0.14466 to 0.13576, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.13576\n",
      "\n",
      "Epoch 00010: loss improved from 0.13576 to 0.13037, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.13037\n",
      "\n",
      "Epoch 00026: loss improved from 0.13037 to 0.13020, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00030: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000001181490946e-25.\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.13020\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.13020\n",
      "Starting...\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.21219, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00002: loss improved from 0.21219 to 0.19789, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00003: loss improved from 0.19789 to 0.18835, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00004: loss improved from 0.18835 to 0.18109, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.18109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: loss improved from 0.18109 to 0.17121, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00007: loss improved from 0.17121 to 0.16014, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00008: loss improved from 0.16014 to 0.12707, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00009: loss improved from 0.12707 to 0.11925, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00010: loss improved from 0.11925 to 0.11279, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00011: loss improved from 0.11279 to 0.11167, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00012: loss improved from 0.11167 to 0.11113, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.11113\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00014: loss improved from 0.11113 to 0.10713, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00015: loss improved from 0.10713 to 0.10143, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.10143\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.10143\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00018: loss improved from 0.10143 to 0.10050, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00021: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00023: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001044244145e-13.\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.10050\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.0000001179769417e-14.\n",
      "\n",
      "Epoch 00030: loss improved from 0.10050 to 0.09948, saving model to ./best_model.hdf5\n",
      "\n",
      "Epoch 00031: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000001518582595e-15.\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00033: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000001095066122e-16.\n",
      "\n",
      "Epoch 00034: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00035: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000830368326e-17.\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.0000000664932204e-18.\n",
      "\n",
      "Epoch 00038: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00039: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000045813705e-19.\n",
      "\n",
      "Epoch 00040: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.000000032889008e-20.\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.0000000490448793e-21.\n",
      "\n",
      "Epoch 00044: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00045: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.0000000692397185e-22.\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.0000000944832675e-23.\n",
      "\n",
      "Epoch 00048: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.09948\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000787060494e-24.\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.09948\n",
      "20min 44s ± 47.2 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "EPOCHS =70\n",
    "MAX_BATCH_SIZE = 256\n",
    "#learning rate reduction\n",
    "MAX_PATIENCE = 2\n",
    "\n",
    "best_filepath ='./best_model.hdf5'\n",
    "\n",
    "#callbacks\n",
    "callback = [ReduceLROnPlateau(patience = MAX_PATIENCE, verbose = 1),ModelCheckpoint(filepath=best_filepath, monitor='loss',verbose=1,save_best_only=True)]\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#train\n",
    "print('Starting...')\n",
    "model.fit(x=X_train,y=y_train,epochs=50,batch_size=128,verbose=0, validation_data=(X_test,y_test), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
